{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91373928-6089-4b46-8318-9da3d026da09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28mself\u001b[39m.mse_sum.assign(\u001b[32m0.\u001b[39m)\n\u001b[32m     38\u001b[39m         \u001b[38;5;28mself\u001b[39m.total_samples.assign(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m model = \u001b[43mget_mnist_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m model.compile(optimizer=\u001b[33m\"\u001b[39m\u001b[33mrmsprop\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     42\u001b[39m               loss=\u001b[33m\"\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     43\u001b[39m               metrics=[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m, RootMeanSquaredError()])\n\u001b[32m     44\u001b[39m model.fit(train_images, \n\u001b[32m     45\u001b[39m           train_labels, \n\u001b[32m     46\u001b[39m           epochs=\u001b[32m3\u001b[39m, \n\u001b[32m     47\u001b[39m           validation_data=(val_images, val_labels))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mget_mnist_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_mnist_model\u001b[39m():            \n\u001b[32m      6\u001b[39m     inputs = keras.Input(shape=(\u001b[32m28\u001b[39m * \u001b[32m28\u001b[39m,))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     features = \u001b[43mlayers\u001b[49m.Dense(\u001b[32m512\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m)(inputs)\n\u001b[32m      8\u001b[39m     features = layers.Dropout(\u001b[32m0.5\u001b[39m)(features)\n\u001b[32m      9\u001b[39m     outputs = layers.Dense(\u001b[32m10\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m)(features)\n",
      "\u001b[31mNameError\u001b[39m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():            \n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()    \n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255 \n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255 \n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric): \n",
    "    def __init__(self, name=\"rmse\", **kwargs):                               \n",
    "        super().__init__(name=name, **kwargs)                                \n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")  \n",
    "        self.total_samples = self.add_weight(                                \n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")  \n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):  \n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])   \n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, \n",
    "          train_labels, \n",
    "          epochs=3, \n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3852ab8-bed0-44a6-9c00-e38c03864761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
